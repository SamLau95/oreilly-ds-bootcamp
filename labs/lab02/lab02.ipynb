{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f63814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code sets up display options, imports, etc.\n",
    "import sys\n",
    "if sys.platform == 'emscripten':\n",
    "    %pip install -q seaborn plotly\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# set up plotting defaults\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats(\"svg\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 3)\n",
    "pio.templates.default = \"simple_white\"\n",
    "\n",
    "# Sam's preferred styles\n",
    "pio.templates[\"sam\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        width=600,\n",
    "        height=400,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+sam\"\n",
    "\n",
    "# display options for numpy and pandas\n",
    "np.set_printoptions(threshold=20, precision=2, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 7)\n",
    "pd.set_option(\"display.max_columns\", 8)\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3749195",
   "metadata": {},
   "source": [
    "# Lab 2: Exploratory Data Analysis\n",
    "\n",
    "**Data Science Bootcamp with Python, Pandas, and Plotly**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f960d1de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf0c1c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### San Diego food safety\n",
    "\n",
    "From [this article](https://inewsource.org/2023/02/09/san-diego-restaurants-food-safety-violations/) ([archive link](https://archive.ph/gz8BL)):\n",
    "\n",
    "> In the last three years, one third of San Diego County restaurants have had at least one major food safety violation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515d84e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 99% Of San Diego Restaurants Earn â€˜A' Grades, Bringing Usefulness of System Into Question\n",
    "\n",
    "From [this article](https://www.nbcsandiego.com/news/local/99-of-san-diego-restaurants-earn-a-grades-bringing-usefulness-of-system-into-question/25381/) ([archive link](https://archive.ph/yB6RU)):\n",
    "\n",
    "> Food held at unsafe temperatures. Employees not washing their hands. Dirty countertops. Vermin in the kitchen. An expired restaurant permit.\n",
    "> \n",
    "> Restaurant inspectors for San Diego County found these violations during a routine health inspection of a diner in La Mesa in November 2016. Despite the violations, the restaurant was awarded a score of 90 out of 100, the lowest possible score to achieve an â€˜Aâ€™ grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed1253",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The data\n",
    "\n",
    "- We downloaded the data about the 1000 restaurants closest to UC San Diego from [here](https://www.sandiegocounty.gov/content/sdc/deh/fhd/ffis/intro.html.html).\n",
    "- We had to download the data as JSON files, then process it into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7850922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "rest_path = Path('data') / 'restaurants.csv'\n",
    "insp_path = Path('data') / 'inspections.csv'\n",
    "viol_path = Path('data') / 'violations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da66a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = pd.read_csv(rest_path)\n",
    "insp = pd.read_csv(insp_path)\n",
    "viol = pd.read_csv(viol_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12562ed1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤”</h3>\n",
    "</div>\n",
    "    \n",
    "The first article said that one third of restaurants had at least one major safety violation.<br>\n",
    "Which DataFrames and columns seem most useful to verify this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49ddcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5ee9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d43f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccfbb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13909895",
   "metadata": {},
   "outputs": [],
   "source": [
    "viol.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e94d7992",
   "metadata": {},
   "outputs": [],
   "source": [
    "viol.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45210f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "167cfec4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduction to `plotly`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74278b0a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `plotly`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c578b5b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've used `plotly` last time briefly, but let's introduce it in more detail now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99283ab4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's a visualization library that enables **interactive** visualizations.\n",
    "\n",
    "<center><img src=\"imgs/plotly.png\" width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961e92f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `plotly`\n",
    "\n",
    "There are a few ways we can use `plotly`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea803e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Using the `plotly.express` syntax.\n",
    "    - `plotly` is very flexible, but it can be verbose; `plotly.express` allows us to make plots quickly.\n",
    "    - See the [**documentation here**](https://plotly.com/python/plotly-express) â€“ it's very rich (there are good examples for almost everything)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e5e20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- By setting `pandas` plotting backend to `'plotly'` (by default, it's `'matplotlib'`) and using the DataFrame `plot` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05421c54",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For now, we'll use `plotly.express` syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0cd91c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Also, use plotly as default plotting engine\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e83ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Initial plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab91195",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's look at the distribution of inspection `'score'`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce396166",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(x=insp['score'])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961b8b9e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How about the distribution of average inspection `'score'` per `'grade'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d098ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = (\n",
    "    insp[['grade', 'score']]\n",
    "    .dropna()\n",
    "    .groupby('grade')\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "# x= and y= are columns of scores. Convenient!\n",
    "px.bar(scores, x='grade', y='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e30b8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the above!\n",
    "scores.plot(kind='bar', x='grade', y='score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49074ddf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploratory data analysis and feature types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011c207",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The data science lifecycle, revisited\n",
    "\n",
    "<center>\n",
    "    <img src=\"imgs/ds-lifecycle.svg\" width=50%>\n",
    "</center>\n",
    "\n",
    "We're at the stage of **understanding the data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47971474",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exploratory data analysis (EDA)\n",
    "\n",
    "- Historically, data analysis was dominated by formal statistics, including tools like confidence intervals, hypothesis tests, and statistical modeling.\n",
    "\n",
    "- In 1977, John Tukey [defined](https://search.worldcat.org/title/3058187) the term **exploratory data analysis**, which described a philosophy for proceeding about data analysis:\n",
    "\n",
    "> Exploratory data analysis is actively incisive, rather than passively descriptive, with real emphasis on the discovery of the unexpected.\n",
    "\n",
    "- Practically, EDA involves, among other things, computing summary statistics and drawing plots to understand the nature of the data at hand.\n",
    "\n",
    "> The greatest gains from data come from surprisesâ€¦ The unexpected is best brought to our attention by **pictures**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42538193",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different feature types\n",
    "\n",
    "<center><img src='imgs/data-types.png' width=90%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65254dfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤”</h3>\n",
    "</div>\n",
    "    \n",
    "What is the **feature type** of each of the following variables?\n",
    "    \n",
    "- `insp['score']`\n",
    "- `insp['grade']`\n",
    "- `viol['violation_accela']`\n",
    "- `viol['major_violation']`\n",
    "- `rest['business_id']`\n",
    "- `rest['opened_date']`\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e79fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb538106",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature types vs. data types\n",
    "\n",
    "- The data type `pandas` uses is not the same as the \"data type\" we talked about just now!\n",
    "    - There's a difference between feature type and computational data type.\n",
    "\n",
    "- Take care when the two don't match up very well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b59abe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas stores these as ints, but they're actually nominal.\n",
    "rest['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f44f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas stores these as strings, but they're actually numeric.\n",
    "rest['opened_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca57115e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a2484",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Four pillars of data cleaning\n",
    "\n",
    "When loading in a dataset, to clean the data â€“ that is, to prepare it for further analysis â€“ we will:\n",
    "\n",
    "1. Perform **data quality checks**.\n",
    "\n",
    "2. Identify and handle **missing values**.\n",
    "\n",
    "3. Perform **transformations**, including converting time series data to **timestamps**.\n",
    "\n",
    "4. Modify **structure** as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733fa0f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Data quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8e40a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data quality checks\n",
    "\n",
    "We often start an analysis by checking the quality of the data.\n",
    "\n",
    "- Scope: Do the data match your understanding of the population? \n",
    "- Measurements and values: Are the values reasonable?\n",
    "- Relationships: Are related features in agreement?\n",
    "- Analysis: Which features might be useful in a future analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd93dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scope\n",
    "\n",
    "Do the data match your understanding of the population?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7bb308",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We were told that we're only looking at the 1000 restaurants closest to UCSD, so the restaurants in `rest` should agree with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b447a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e7ad8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Measurements and values\n",
    "\n",
    "Are the values reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27473ee",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Do the values in the `'grade'` column match what we'd expect grades to look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b53eecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40003f3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What kinds of information does the `insp` DataFrame hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8eccf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d90bb2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What's going on in the `'address'` column of `rest`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "127e1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there multiple restaurants with the same address?\n",
    "rest['address'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7e6b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps all rows with duplicate addresses.\n",
    "(\n",
    "    rest\n",
    "    .groupby('address')\n",
    "    .filter(lambda df: df.shape[0] >= 2)\n",
    "    .sort_values('address')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab5e5ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the same thing as above!\n",
    "(\n",
    "    rest[rest.duplicated(subset=['address'], keep=False)]\n",
    "    .sort_values('address')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e706987",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Relationships\n",
    "\n",
    "Are related features in agreement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd1bce",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Do the `'address'`es and `'zip'` codes in `rest` match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9ad88b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest[['address', 'zip']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823ea2bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What about the `'score'`s and `'grade'`s in `insp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7bb71c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp[['score', 'grade']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1925e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Analysis\n",
    "\n",
    "Which features might be useful in a future analysis?\n",
    "\n",
    "- We're most interested in:\n",
    "    - These columns in the `rest` DataFrame: `'business_id'`, `'name'`, `'address'`, `'zip'`, and `'opened_date'`.\n",
    "    - These columns in the `insp` DataFrame: `'business_id'`, `'inspection_id'`, `'score'`, `'grade'`, `'completed_date'`, and `'status'`.\n",
    "    - These columns in the `viol` DataFrame: `'inspection_id'`, `'violation'`, `'major_violation'`, `'violation_text'`, and `'violation_accela'`.\n",
    "\n",
    "- Also, let's rename a few columns to make them easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65abaffb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ðŸ’¡ Pro-Tip: Using `pipe`\n",
    "\n",
    "When we manipulate DataFrames, it's best to define individual functions for each step, then use the `pipe` **method** to chain them all together.\n",
    "\n",
    "The `pipe` DataFrame method takes in a function, which itself takes in a DataFrame and returns a DataFrame.\n",
    "\n",
    "- In practice, we would add functions one by one to the top of a notebook, then `pipe` them all.\n",
    "- For today, will keep re-running `pipe` to show data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11375c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_rest(rest):\n",
    "    return rest[['business_id', 'name', 'address', 'zip', 'opened_date']]\n",
    "\n",
    "rest = (\n",
    "    pd.read_csv(rest_path)\n",
    "    .pipe(subset_rest)\n",
    ")\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "285549e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the above â€“ but the above makes it easier to chain more .pipe calls afterwards.\n",
    "subset_rest(pd.read_csv(rest_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b94df6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use `pipe` to keep (and rename) the subset of the columns we care about in the other two DataFrames as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3c0d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_insp(insp):\n",
    "    return (\n",
    "        insp[['business_id', 'inspection_id', 'score', 'grade', 'completed_date', 'status']]\n",
    "        .rename(columns={'completed_date': 'date'})\n",
    "    )\n",
    "\n",
    "insp = (\n",
    "    pd.read_csv(insp_path)\n",
    "    .pipe(subset_insp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a679d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_viol(viol):\n",
    "    return (\n",
    "        viol[['inspection_id', 'violation', 'major_violation', 'violation_accela']]\n",
    "        .rename(columns={'violation': 'kind',\n",
    "                         'major_violation': 'is_major',\n",
    "                         'violation_accela': 'violation'})\n",
    "    )\n",
    "\n",
    "viol = (\n",
    "    pd.read_csv(viol_path)\n",
    "    .pipe(subset_viol)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14a796",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combining the restaurant data\n",
    "\n",
    "Let's join all three DataFrames together so that we have all the data in a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d068ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_restaurant_data():\n",
    "    return (\n",
    "        rest\n",
    "        .merge(insp, on='business_id', how='left')\n",
    "        .merge(viol, on='inspection_id', how='left')\n",
    "    )\n",
    "\n",
    "df = merge_all_restaurant_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b3551",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤”</h3>\n",
    "</div>\n",
    "    \n",
    "Why should the function above use two left joins? What would go wrong if we used other kinds of joins?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48794346",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c075ea2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missing values\n",
    "\n",
    "Next, it's important to check for and handle missing values, as they can have a big effect on your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d10c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp[['score', 'grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9bbd7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proportion of values in each column that are missing.\n",
    "insp.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38066714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Why are there null values here?\n",
    "# insp['inspection_id'] and viol['inspection_id'] don't have any null values...\n",
    "df[df['inspection_id'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c26065",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are many ways of handling missing values, which we'll cover in an entire lecture next week. But a good first step is to check how many there are!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caabc12",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Transformations and timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd32d87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformations and timestamps\n",
    "\n",
    "From last class:\n",
    "\n",
    "> A transformation results from performing some operation on every element in a sequence, e.g. a Series.\n",
    "\n",
    "It's often useful to look at ways of transforming your data to make it easier to work with.\n",
    "\n",
    "- Type conversions (e.g. changing the string `\"$2.99\"` to the number `2.99`).\n",
    "\n",
    "- Unit conversion (e.g. feet to meters).\n",
    "\n",
    "- Extraction (Getting `'vermin'` out of `'Vermin Violation Recorded on 10/10/2023'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07015513",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating timestamps\n",
    "\n",
    "Most commonly, we'll parse dates into `pd.Timestamp` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc517a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dtype!\n",
    "insp['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ea13235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This magical string tells Python what format the date is in.\n",
    "# For more info: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "date_format = '%Y-%m-%d'\n",
    "pd.to_datetime(insp['date'], format=date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6434da05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Another advantage of defining functions is that we can reuse this function\n",
    "# for the 'opened_date' column in `rest` if we wanted to.\n",
    "def parse_dates(insp, col):\n",
    "    date_format = '%Y-%m-%d'\n",
    "    dates = pd.to_datetime(insp[col], format=date_format)\n",
    "    return insp.assign(**{col: dates})\n",
    "\n",
    "insp = (\n",
    "    pd.read_csv(insp_path)\n",
    "    .pipe(subset_insp)\n",
    "    .pipe(parse_dates, 'date')\n",
    ")\n",
    "\n",
    "# We should also remake df, since it depends on insp.\n",
    "# Note that the new insp is used to create df!\n",
    "df = merge_all_restaurant_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "152fb473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dtype now!\n",
    "df['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb95ba03",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Working with timestamps\n",
    "\n",
    "- We often want to adjust granularity of timestamps to see overall trends, or seasonality.\n",
    "- Use the `resample` method in `pandas` ([documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects)).\n",
    "    - Think of it like a version of `groupby`, but for timestamps.\n",
    "    - For instance, `insp.resample('2W', on='date')` separates every two weeks of data into a different group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e221031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp.resample('2W', on='date')['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "328d6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are those numbers coming from?\n",
    "insp[\n",
    "    (insp['date'] >= pd.Timestamp('2020-01-05')) &\n",
    "    (insp['date'] < pd.Timestamp('2020-01-19'))\n",
    "]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "978aa92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(insp.resample('2W', on='date')\n",
    " .size()\n",
    " .plot(title='Number of Inspections Over Time')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c12bb5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `.dt` accessor\n",
    "\n",
    "Like with Series of strings, `pandas` has a `.dt` accessor for properties of timestamps ([documentation](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dt-accessors))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3deaa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bd7eb9a9",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "insp['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c4bf0fdb",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "insp['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71bef496",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "dow_counts = insp['date'].dt.dayofweek.value_counts()\n",
    "fig = px.bar(dow_counts)\n",
    "fig.update_xaxes(tickvals=np.arange(7), ticktext=['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce0d17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning: Modifying structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b44cf0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reshaping DataFrames\n",
    "\n",
    "We often **reshape** the DataFrame's structure to make it more convenient for analysis. For example, we can:\n",
    "\n",
    "- Simplify structure by removing columns or taking a set of rows for a particular period of time or geographic area.\n",
    "    - We already did this!\n",
    "\n",
    "- Adjust granularity by aggregating rows together.\n",
    "    - To do this, use `groupby` (or `resample`, if working with timestamps).\n",
    "\n",
    "- Reshape structure, most commonly by using the DataFrame `melt` method to un-pivot a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f5504c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `melt`\n",
    "\n",
    "- The `melt` method is common enough that we'll give it a special mention.\n",
    "- We'll often encounter pivot tables (esp. from government data), which we call *wide* data.\n",
    "- The methods we've introduced work better with *long-form* data, or *tidy* data.\n",
    "- To go from wide to long, `melt`.\n",
    "\n",
    "<center><img src='imgs/wide-vs-long.svg' width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5571c5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example usage of `melt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8a2a32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_example = pd.DataFrame({\n",
    "    'Year': [2001, 2002],\n",
    "    'Jan': [10, 130],\n",
    "    'Feb': [20, 200],\n",
    "    'Mar': [30, 340]\n",
    "}).set_index('Year')\n",
    "wide_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6303bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_example.melt(ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fa0dbb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a67278",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ðŸ¤”</h3>\n",
    "</div>\n",
    "    \n",
    "What questions do you want me to try and answer with the data? I'll start with a single pre-prepared question, and then answer student questions until we run out of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561edf25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example question: Can we rank restaurants by their number of violations? How about separately for each zip code?\n",
    "\n",
    "And why would we want to do that? ðŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441bc84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb7548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
